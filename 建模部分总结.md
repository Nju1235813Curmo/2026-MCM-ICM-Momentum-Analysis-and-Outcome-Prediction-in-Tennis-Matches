# 1.数据预处理

> pre_work.py :做建模准备  
> seq_len_sensitivity.py：用来选择合适的序列长度，最终选择20

**2024_Wimbledon_featured_matches.csv**，该数据集记录了比赛中每一分的详细信息，包括比分、发球落点、击球类型、速度、回合数、制胜分、失误等共 40+ 个字段。为了保证模型能够处理这些原始字段，我对数据进行了系统的预处理和特征构建。
通过对官方逐分数据进行清洗、时间解析、类别编码、球员 embedding 构建和序列化处理，我们最终得到了可直接用于深度学习模型的时序特征，为后续的 LSTM、GRU 和 Transformer 预测模型奠定了完整的数据基础。

## （1）数据清洗

为了避免模型因缺失而报错，我们统一将缺失值（如有）填为 0 或使用类别编码中的 “-1”。

原始字段 elapsed_time 的格式为 "HH:MM:SS" 字符串，不适合直接建模。我们将其转换为 总秒数（elapsed_seconds），这样模型就可以直接学习时间随比赛推进的规律。

## （2）类别变量编码

逐分数据中有多个字段并不是数字，而是类别，例如：

- p1_score, p2_score（0, 15, 30, 40, AD）
- winner_shot_type（发球、正拍、反拍、截击等）
- serve_width（发球落点：T区 / 身体 / 边区）
- serve_depth（深球 / 浅球）
- return_depth（深区 / 中区 / 掉短）

这些字段不能直接输入深度学习模型，因此全部使用 类别编码（category code） 转为整数：

- “0,15,30,40,AD” → 0/1/2/3/4
- “T/Body/Wide” → 0/1/2
- 无指定类型 → 0 或 -1

这样模型就能把这些击球行为当作离散属性进行学习。

## （3）构造标签字段

原始数据中使用 point_victor 表示赢得该分的球员：

- 1：player1 赢分
- 2：player2 赢分

我们把它转成二分类任务所需的标签，即player1赢分记为1，player2赢分记为2

```
p1_won = 1 if point_victor == 1 else 0
```

## （4）建立球员 Embedding ID

为了让模型理解“球员实力差异”，我们为每个球员创建一个唯一的 ID：

```
p1_id = player1 的数字 ID  
p2_id = player2 的数字 ID

```

并在模型中加入球员 embedding，使得不同球员有不同的“实力向量”，使模型可以自动学习球员的风格、稳定性、抗压能力等长期特征，来提升模型的效果

## (5)选择特征

在做特征工程时，我们把以下内容直接排除：
match_id（字符串），player1 / player2（字符串），原始 elapsed_time（字符串格式），p1_won（标签），point_victor（原始标签），p1_id / p2_id（embedding 单独输入模型）

剩下的字段全部作为有效逐分特征，包括：
发球宽度/深度，击球类型，回合数（rally_count），发球速度（speed_mph），非受迫性失误、制胜分、双误、ACE，比分信息：p1_score/p2_score, p1_games/p2_games, p1_sets/p2_sets，球员跑动距离，时间进度（elapsed_seconds），正在发球的球员（server）

这些字段共同构成了模型理解网球势头变化所需的全部底层信息

## (6)构建逐分时间序列（序列长度 = 20）

为了让模型学习“势头（momentum）”，我们不是单独看某一分，而是看 最近 20 分的连续序列
为了选择序列长度，我们做了**seq_len_sensitivity.py**来比较不同序列长度(seq_lens = [5, 10, 15, 20, 30, 40])下模型的MAE,RMSE,F1,AUC，最终按照模型的性能结果选择了20

对每一场比赛，我们按顺序排列：

```

(set_no, game_no, point_no)

```

并生成滑动窗口序列：

```

[点 1 ~ 点20] → 预测点21  
[点 2 ~ 点21] → 预测点22  
……

```

最后得到约 6000 条有效训练序列，包含了比赛中的完整动态变化。

# 2. 主模型搭建 

> train_test.py：用来做模型训练预处理
> train_lstm.py/improved_train_lstm.py：用来训练lstm和调优版lstm模型
> train_gru.py：用来训练GRU模型
> train_transformer.py：用来训练transformer模型
> evaluate_model.py：用来评估和对比调优版LSTM/GRU/transformer三个模型的性能

研究的目标是根据逐分特征预测“下一分由谁获得”，并借助模型输出的逐分胜率变化构建势头（momentum）曲线。因此，我们采用了三类典型的序列模型：LSTM、GRU 和 Transformer。三种模型的输入一致，区别在于其对时间序列的建模方式不同。

## (1)输入与输出结构

所有模型的输入是长度为 20 的逐分序列，每个时间步包含约 38 个特征，包括但不限于：

- 发球方向、发球深度
- 击球类型
- 回合数、发球速度
- 制胜分、失误、双误、ACE
- 当前盘数 / 局数
- 比分（p1_score / p2_score）
- 谁在发球（server）
- 球员 embedding（长期能力）等

模型的输出是p1_win_prob ∈ [0,1]，（下一分由 player1 获胜的概率）

## （2）LSTM模型

LSTM（Long Short-Term Memory）适用于学习长短期依赖关系。网球比赛中连续几分的走势往往会影响下一分，因此 LSTM 能够较好地捕捉这种“连续性”和“节奏变化”。

模型结构：

- 输入序列（batch_size × 20 × feature_dim）
- LSTM（双层）
- Dropout（防止过拟合）
- 全连接层（输出 p1_win_prob）

特点：

- 能处理较长的依赖
- 对噪声敏感，对超参数（隐藏维度 / dropout）依赖更强
- 训练速度较慢

在本任务中，LSTM 表现中等，但比 Transformer 稳定

## （3）GRU 模型（表现最佳）

GRU（Gated Recurrent Unit）是 LSTM 的简化版本，结构更轻、更快，且在短序列任务中性能优秀。网球逐分数据的序列较短、噪声多，因此 GRU 更适合本任务。

模型结构：

- Player Embedding（为每位球员学习一个向量，表示其长期实力）
- 输入特征与两个选手 embedding 拼接
- 双层 GRU（bidirectional GRU）
- 全连接网络输出预测概率

特点：

- 收敛更快
- 对短序列更稳定
- 表现优于 LSTM
- 最符合网球逐分数据的结构

实际训练中，GRU 的 F1、AUC 指标均为最高，是本研究表现最好的主模型。同时也将GRU作为用于势头分析的模型。

## （4）Transformer模型

Transformer 通过 Self-Attention 学习序列内部的全局依赖，本质上是为长序列任务设计的（如 NLP）。
我们构建了一个轻量版 Transformer 包含：

- Position Encoding
- Multi-Head Attention
- Feed Forward Layer
- 最终全连接输出

特点：

- 理论上可以捕获更长的依赖关系
- 但网球逐分数据序列较短（仅 20），且样本量较小
- 模型复杂度高，容易过拟合
- 最终训练效果不如 LSTM/GRU

## （5）三模型性能对比（选择GRU）

| 模型                 | MAE    | RMSE   | F1-score | AUC     |
| ------------------ | ------ | ------ | -------- | ------- |
| **LSTM**           | 0.4491 | 0.4840 | 0.6265   | 0.6575  |
| **GRU**            | 0.4517 | 0.4810 | ⭐0.6420  | ⭐0.6629 |
| **Transformer_v2** | 0.4521 | 0.5056 | 0.5441   | 0.6254  |

# 3. 势头分析与建模

> momentum_analysis.py：不含球员embedding的势头轻量快速分析模型
> **momentum_model_with_player_embedding.py：从 Wimbledon 原始逐分数据重新构建全流程势头模型（含球员 embedding），此模型在程序里面改比赛场次，可以换不同场次的比赛来进行分析**

在完成逐分预测模型训练之后，我们进一步利用模型输出的逐分胜率来构建网球比赛中的“势头”（momentum）曲线。势头是网球比赛中非常关键且主观的概念，通常表现为选手在一段时间内持续得分、连续犯错、连续施压等状态的累积变化。

## 1. 基于逐分预测的势头定义

我们使用 GRU 主模型对每一个 point 预测：p = P( player1 wins next point )

这类逐分预测概率本质上反映了模型根据当前局面判断哪位选手更有优势。因此，连续概率的变化就可以反映势头的上升或下滑。

为了让势头变化更加平滑，我们对原始逐分预测进行了滑动平均处理：momentum(t) = mean( p[t - k + 1 ... t] ), 其中 k = 5
也就是使用最近 5 分（可理解为“局部节奏”）来估计当前时刻的势头。

## 2. 势头曲线构建流程

构建势头曲线的步骤如下：
（1）按比赛逐分排序
按 set_no、game_no、point_no 对每场比赛重新排序，确保模型预测与比赛进程一致。

（2）运行 GRU 模型生成逐分预测
对每一分生成：pred_prob = GRU(sequence_last_20_points)
得到概率序列：[0.51, 0.48, 0.46, 0.60, 0.72, ...]

（3）使用滑动窗口平滑势头（momentum smoothing）
使走势具有可解释性，减少单个点的噪声影响，最终得到势头曲线。

（4）保存势头数据与曲线图
输出 CSV（包括每分、每局、每盘的趋势）
绘制 momentum 曲线图（折线图）
标记可能的反转点（见下一节）

通过这样的处理，我们得到一个可视化、可分析的势头变化轨迹。

## 3. 势头反转点的识别

我们设定：当势头从上升趋势变为快速下降，或从下降趋势变为快速上升，且变化幅度超过阈值（如 Δmomentum > 0.08），就认为发生了一次“势头反转”。

这些反转点通常对应：一局被破发（break）、连续失误导致“掉节奏”、关键分被对手拿下、连续赢下长回合的心理优势

在分析中我们标记了每场比赛的反转点，方便解释选手状态变化。

## 4. 按局（game-level）预测与势头关系

我们进一步将逐分预测的概率按 game 聚合：game_prob = mean(p of points in this game)

如果：game_prob > 0.5 → 预测 P1 赢下该局，game_prob ≤ 0.5 → 预测 P2 赢下该局，得到每一局的预测胜负，并和真实结果对比。
总体预测准确率约为：按局（game）预测准确率：0.5341（共 1099 局）

该结果说明：虽然单分较难预测（受随机性影响），但将逐分势头聚合后，能够有效反映每局的走势和优势方向。

换句话说：
势头不仅能显示比赛状态变化，也能用于实际判断比赛进程（按局预测）。

## 5. 模型势头分析的意义

本研究的势头分析具有以下价值：

（1）从客观数据重建“势头”这一主观概念，摆脱以往只能依靠观众、教练、解说的感性判断。

（2）将深度学习的 point-level 输出与 tennis momentum 理论结合，模型输出天然具有连续性，可以用于棋盘式 momentum tracking。

（3）反转点有助于发现“关键时刻”

可以分析：比赛在哪里失控？哪个点之后势头明显偏向另一方？哪个局面选手表现明显下降或提升？

（4）为比赛策略与教练分析提供参考

比如：某选手遇到长回合势头下降，某选手在关键分更容易丢分，从某个局起势头被完全压制，说明可能存在体能/心理问题，这些洞见在实际比赛分析中非常有价值。
